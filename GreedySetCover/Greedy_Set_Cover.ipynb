{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3415123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Approx on test*.in ---\n",
      "Processing: test1\n",
      "  Result Quality: 2, Optimal: 2, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: test2\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: test3\n",
      "  Result Quality: 7, Optimal: 7, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: test4\n",
      "  Result Quality: 5, Optimal: 5, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: test5\n",
      "  Result Quality: 5, Optimal: 5, RelErr: 0.0000, Time: 0.0000s\n",
      "\n",
      "--- Running Approx on small*.in ---\n",
      "Processing: small1\n",
      "  Result Quality: 5, Optimal: 5, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small10\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small11\n",
      "  Result Quality: 5, Optimal: 5, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small12\n",
      "  Result Quality: 4, Optimal: 4, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small13\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small14\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small15\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small16\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small17\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small18\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small2\n",
      "  Result Quality: 4, Optimal: 4, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small3\n",
      "  Result Quality: 6, Optimal: 6, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small4\n",
      "  Result Quality: 5, Optimal: 5, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small5\n",
      "  Result Quality: 6, Optimal: 6, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small6\n",
      "  Result Quality: 4, Optimal: 4, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small7\n",
      "  Result Quality: 4, Optimal: 4, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small8\n",
      "  Result Quality: 3, Optimal: 3, RelErr: 0.0000, Time: 0.0000s\n",
      "Processing: small9\n",
      "  Result Quality: 4, Optimal: 4, RelErr: 0.0000, Time: 0.0000s\n",
      "\n",
      "--- Running Approx on large*.in ---\n",
      "Processing: large1\n",
      "  Result Quality: 83, Optimal: 83, RelErr: 0.0000, Time: 0.4555s\n",
      "Processing: large10\n",
      "  Result Quality: 319, Optimal: 319, RelErr: 0.0000, Time: 0.3785s\n",
      "Processing: large11\n",
      "  Result Quality: 56, Optimal: 56, RelErr: 0.0000, Time: 0.0845s\n",
      "Processing: large12\n",
      "  Result Quality: 18, Optimal: 18, RelErr: 0.0000, Time: 0.0037s\n",
      "Processing: large2\n",
      "  Result Quality: 21, Optimal: 21, RelErr: 0.0000, Time: 0.0016s\n",
      "Processing: large3\n",
      "  Result Quality: 17, Optimal: 17, RelErr: 0.0000, Time: 0.0075s\n",
      "Processing: large4\n",
      "  Result Quality: 153, Optimal: 153, RelErr: 0.0000, Time: 0.1580s\n",
      "Processing: large5\n",
      "  Result Quality: 8, Optimal: 8, RelErr: 0.0000, Time: 0.0043s\n",
      "Processing: large6\n",
      "  Result Quality: 7, Optimal: 7, RelErr: 0.0000, Time: 0.0085s\n",
      "Processing: large7\n",
      "  Result Quality: 172, Optimal: 172, RelErr: 0.0000, Time: 0.4516s\n",
      "Processing: large8\n",
      "  Result Quality: 6, Optimal: 6, RelErr: 0.0000, Time: 0.0016s\n",
      "Processing: large9\n",
      "  Result Quality: 16, Optimal: 16, RelErr: 0.0000, Time: 0.0070s\n",
      "\n",
      "--- Experiment Complete ---\n",
      "\n",
      "--- Results Summary ---\n",
      "   Instance  Method    Time  Quality  Optimal RelErr_Display\n",
      "0     test1  Approx  0.0000        2        2         0.0000\n",
      "1     test2  Approx  0.0000        3        3         0.0000\n",
      "2     test3  Approx  0.0000        7        7         0.0000\n",
      "3     test4  Approx  0.0000        5        5         0.0000\n",
      "4     test5  Approx  0.0000        5        5         0.0000\n",
      "5    small1  Approx  0.0000        5        5         0.0000\n",
      "6   small10  Approx  0.0000        3        3         0.0000\n",
      "7   small11  Approx  0.0000        5        5         0.0000\n",
      "8   small12  Approx  0.0000        4        4         0.0000\n",
      "9   small13  Approx  0.0000        3        3         0.0000\n",
      "10  small14  Approx  0.0000        3        3         0.0000\n",
      "11  small15  Approx  0.0000        3        3         0.0000\n",
      "12  small16  Approx  0.0000        3        3         0.0000\n",
      "13  small17  Approx  0.0000        3        3         0.0000\n",
      "14  small18  Approx  0.0000        3        3         0.0000\n",
      "15   small2  Approx  0.0000        4        4         0.0000\n",
      "16   small3  Approx  0.0000        6        6         0.0000\n",
      "17   small4  Approx  0.0000        5        5         0.0000\n",
      "18   small5  Approx  0.0000        6        6         0.0000\n",
      "19   small6  Approx  0.0000        4        4         0.0000\n",
      "20   small7  Approx  0.0000        4        4         0.0000\n",
      "21   small8  Approx  0.0000        3        3         0.0000\n",
      "22   small9  Approx  0.0000        4        4         0.0000\n",
      "23   large1  Approx  0.4555       83       83         0.0000\n",
      "24  large10  Approx  0.3785      319      319         0.0000\n",
      "25  large11  Approx  0.0845       56       56         0.0000\n",
      "26  large12  Approx  0.0037       18       18         0.0000\n",
      "27   large2  Approx  0.0016       21       21         0.0000\n",
      "28   large3  Approx  0.0075       17       17         0.0000\n",
      "29   large4  Approx  0.1580      153      153         0.0000\n",
      "30   large5  Approx  0.0043        8        8         0.0000\n",
      "31   large6  Approx  0.0085        7        7         0.0000\n",
      "32   large7  Approx  0.4516      172      172         0.0000\n",
      "33   large8  Approx  0.0016        6        6         0.0000\n",
      "34   large9  Approx  0.0070       16       16         0.0000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import glob # To easily find files matching a pattern\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def parse_set_cover_instance(filename):\n",
    "    \"\"\"\n",
    "    Parses the input file for the Set Cover instance.\n",
    "    Args:\n",
    "        filename (str): The path to the input .in file.\n",
    "    Returns:\n",
    "        tuple: (universe_size, subsets)\n",
    "               - universe_size (int): Number of elements in the universe (n).\n",
    "               - subsets (list): A list of sets, where each set contains the elements\n",
    "                                 it covers. Indices correspond to the subset index + 1.\n",
    "    \"\"\"\n",
    "    subsets = []\n",
    "    universe_size = 0\n",
    "    num_subsets = 0\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # Read the first line: n m\n",
    "            line1 = f.readline().strip().split()\n",
    "            if len(line1) == 2:\n",
    "                universe_size = int(line1[0])\n",
    "                num_subsets = int(line1[1]) #\n",
    "            else:\n",
    "                 print(f\"Error: First line format incorrect in {filename}\")\n",
    "                 return None, None\n",
    "\n",
    "            # Read subsequent lines for subsets\n",
    "            for i in range(num_subsets): # Use index i for subset number\n",
    "                 line = f.readline().strip().split()\n",
    "                 # First element is size |Si|, rest are elements\n",
    "                 # Convert elements to integers, handle potential errors\n",
    "                 try:\n",
    "                      if not line: # Handle empty lines if they occur\n",
    "                          print(f\"Warning: Empty line {i+2} encountered in {filename}\")\n",
    "                          continue\n",
    "                      # Expecting size followed by elements\n",
    "                      # size = int(line[0]) # We don't strictly need the size, just the elements\n",
    "                      elements = set(map(int, line[1:]))\n",
    "                      subsets.append(elements)\n",
    "                 except (ValueError, IndexError) as e:\n",
    "                      print(f\"Error parsing subset line {i+2} in {filename}: {e}. Line content: '{' '.join(line)}'\")\n",
    "                      return None, None # Abort parsing on error\n",
    "\n",
    "\n",
    "        # Basic validation\n",
    "        if len(subsets) != num_subsets:\n",
    "             # This might trigger if empty lines were skipped, adjust logic if needed\n",
    "             print(f\"Warning: Mismatch between expected ({num_subsets}) and read ({len(subsets)}) subsets in {filename}\")\n",
    "             # Decide if this is critical; for now, allow continuing\n",
    "\n",
    "        return universe_size, subsets\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found: {filename}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file {filename}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def read_optimal_value(filename):\n",
    "    \"\"\"\n",
    "    Reads the optimal solution value from the .out file.\n",
    "    MODIFIED: Assumes the first line contains space-separated indices of the\n",
    "    optimal solution, and the optimal VALUE is the COUNT of these indices.\n",
    "    Args:\n",
    "        filename (str): The path to the output .out file.\n",
    "    Returns:\n",
    "        int or None: The optimal number of subsets (count of indices on line 1),\n",
    "                     or None if file not found/readable or format is unexpected.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            first_line = f.readline().strip()\n",
    "            # Split the first line by space - these are assumed to be indices\n",
    "            parts = first_line.split()\n",
    "            # The optimal value is the number of indices listed\n",
    "            # Handle empty line case: if parts is empty, count is 0.\n",
    "            opt_value = len(parts)\n",
    "            return opt_value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Optimal value file not found: {filename}. Cannot calculate RelErr.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # General catch-all for other file reading errors\n",
    "        print(f\"Error reading optimal value file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def write_solution_file(filename_base, method, cutoff, seed, solution_indices, quality):\n",
    "    \"\"\"\n",
    "    Writes the solution file in the specified format.\n",
    "    Args:\n",
    "        filename_base (str): Base name of the instance (e.g., 'test1').\n",
    "        method (str): Algorithm used ('Approx' for greedy).\n",
    "        cutoff (int): Cutoff time (relevant for other algos, included for consistency).\n",
    "        seed (int): Random seed (relevant for other algos).\n",
    "        solution_indices (list): List of 1-based indices of selected subsets.\n",
    "        quality (int): The number of subsets selected (size of the cover).\n",
    "    \"\"\"\n",
    "    # Format: <instance>_<method>_<cutoff>[-<randSeed>].sol\n",
    "    # Seed is omitted for deterministic methods like greedy\n",
    "    sol_filename = f\"{filename_base}_{method}_{cutoff}.sol\"\n",
    "\n",
    "    try:\n",
    "        with open(sol_filename, 'w') as f:\n",
    "            # Line 1: quality (minimal size)\n",
    "            f.write(f\"{quality}\\n\")\n",
    "            # Line 2: list of indices (space-separated) - Ensure indices are strings\n",
    "            f.write(\" \".join(map(str, solution_indices)) + \"\\n\")\n",
    "        # print(f\"Solution file written: {sol_filename}\") # Optional: uncomment for verbose output\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing solution file {sol_filename}: {e}\")\n",
    "\n",
    "\n",
    "# --- Greedy Set Cover Algorithm ---\n",
    "\n",
    "def greedy_set_cover(universe_size, subsets):\n",
    "    \"\"\"\n",
    "    Implements the Greedy Set Cover algorithm.\n",
    "    Args:\n",
    "        universe_size (int): Number of elements in the universe (n).\n",
    "        subsets (list): A list of sets, where each set contains the elements it covers.\n",
    "                        Indices in this list are 0-based.\n",
    "    Returns:\n",
    "        tuple: (cover_indices, covered_elements_count, execution_time)\n",
    "               - cover_indices (list): 1-based indices of the subsets in the final cover.\n",
    "               - covered_elements_count (int): Number of unique elements covered.\n",
    "               - execution_time (float): Time taken in seconds.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Elements that still need to be covered (1 to universe_size)\n",
    "    uncovered_elements = set(range(1, universe_size + 1))\n",
    "    # The collection of subsets chosen for the cover (store their 1-based indices)\n",
    "    cover_indices = []\n",
    "    # Keep track of subsets still available for selection.\n",
    "    # Store as list of tuples: (original_1_based_index, set_of_elements)\n",
    "    # We need the original index (1-based) for the final output.\n",
    "    remaining_subsets = [(i + 1, s.copy()) for i, s in enumerate(subsets)]\n",
    "    # Keep a set of selected 1-based indices to prevent duplicates if logic allows\n",
    "    selected_indices_set = set()\n",
    "\n",
    "    while uncovered_elements and remaining_subsets:\n",
    "        best_subset_original_index = -1\n",
    "        elements_covered_by_best = set()\n",
    "        max_newly_covered_count = -1\n",
    "        best_subset_internal_index = -1 # Index within remaining_subsets list\n",
    "\n",
    "        # Find the subset that covers the most *currently uncovered* elements\n",
    "        for i, (original_index, subset_elements) in enumerate(remaining_subsets):\n",
    "            newly_covered = subset_elements.intersection(uncovered_elements)\n",
    "            num_newly_covered = len(newly_covered)\n",
    "\n",
    "            # Greedy choice: Maximize newly covered elements.\n",
    "            # Tie-breaking (optional but good practice): smallest original index, or smallest set size?\n",
    "            # Standard greedy usually doesn't specify tie-breaking, pick first max found.\n",
    "            if num_newly_covered > max_newly_covered_count:\n",
    "                max_newly_covered_count = num_newly_covered\n",
    "                elements_covered_by_best = newly_covered\n",
    "                best_subset_original_index = original_index\n",
    "                best_subset_internal_index = i # Store index *in remaining_subsets*\n",
    "\n",
    "        # Check if we could find any subset covering new elements\n",
    "        if max_newly_covered_count <= 0:\n",
    "            # No remaining subset can cover any more uncovered elements.\n",
    "            if uncovered_elements:\n",
    "                 # This is normal if a full cover is impossible with the given subsets\n",
    "                 pass # Don't print warning unless it's unexpected\n",
    "            break # Stop the algorithm\n",
    "\n",
    "        # Add the best subset found to our cover (use original 1-based index)\n",
    "        if best_subset_original_index not in selected_indices_set:\n",
    "             cover_indices.append(best_subset_original_index)\n",
    "             selected_indices_set.add(best_subset_original_index)\n",
    "\n",
    "        # Remove the covered elements from the uncovered set\n",
    "        uncovered_elements.difference_update(elements_covered_by_best)\n",
    "\n",
    "        # Remove the chosen subset from *further* consideration in this run.\n",
    "        # Pop using the index within the remaining_subsets list.\n",
    "        if best_subset_internal_index != -1:\n",
    "            remaining_subsets.pop(best_subset_internal_index)\n",
    "        else:\n",
    "             # This case should ideally not be reached if max_newly_covered_count > 0\n",
    "             print(f\"Error logic: Could not find internal index for chosen subset {best_subset_original_index}\")\n",
    "             break\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Final check on coverage (informational)\n",
    "    final_covered_count = universe_size - len(uncovered_elements)\n",
    "    if uncovered_elements:\n",
    "         print(f\"Info: Algorithm finished. {len(uncovered_elements)} elements remain uncovered. (Universe size: {universe_size}, Covered: {final_covered_count})\")\n",
    "\n",
    "    # Return 1-based indices, count of elements actually covered, and time\n",
    "    return sorted(cover_indices), final_covered_count, execution_time # Sort indices for consistent output\n",
    "\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "\n",
    "def run_experiment(data_dir, instance_pattern, method, cutoff, seed=None):\n",
    "    \"\"\"\n",
    "    Runs the greedy algorithm on all instances matching the pattern.\n",
    "    Args:\n",
    "        data_dir (str): Directory containing the data files.\n",
    "        instance_pattern (str): Glob pattern for instance files (e.g., 'test*.in').\n",
    "        method (str): Algorithm identifier ('Approx').\n",
    "        cutoff (int): Cutoff time (nominal for greedy).\n",
    "        seed (int): Random seed (nominal for greedy).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Ensure output directory exists\n",
    "    output_dir = \"output\"\n",
    "    if not os.path.exists(output_dir):\n",
    "         os.makedirs(output_dir)\n",
    "\n",
    "    input_files = sorted(glob.glob(os.path.join(data_dir, instance_pattern)))\n",
    "\n",
    "    if not input_files:\n",
    "        print(f\"Warning: No input files found for pattern: {instance_pattern} in {data_dir}\")\n",
    "        return results\n",
    "\n",
    "    print(f\"\\n--- Running {method} on {instance_pattern} ---\")\n",
    "\n",
    "    for in_file in input_files:\n",
    "        base_name = os.path.basename(in_file).replace('.in', '')\n",
    "        out_file = os.path.join(data_dir, base_name + '.out')\n",
    "        print(f\"Processing: {base_name}\")\n",
    "\n",
    "        # 1. Parse instance\n",
    "        universe_size, subsets = parse_set_cover_instance(in_file)\n",
    "        if universe_size is None or subsets is None:\n",
    "            print(f\"Skipping {base_name} due to parsing error.\")\n",
    "            results.append({'Instance': base_name, 'Time': 0, 'Quality': 'Error', 'Optimal': 'N/A', 'RelErr': 'N/A', 'Method': method})\n",
    "            continue\n",
    "\n",
    "        # 2. Read optimal value (for RelErr calculation) - uses updated logic\n",
    "        opt_value = read_optimal_value(out_file)\n",
    "\n",
    "        # 3. Run Greedy Algorithm\n",
    "        cover_indices, covered_count, exec_time = greedy_set_cover(universe_size, subsets)\n",
    "        quality = len(cover_indices) # The size of the cover found by the algorithm\n",
    "\n",
    "        # Check if algorithm covered everything (important for correctness)\n",
    "        if covered_count < universe_size:\n",
    "            print(f\"  WARNING: Greedy algorithm did not cover all elements for {base_name}. Universe: {universe_size}, Covered: {covered_count}\")\n",
    "\n",
    "\n",
    "        # 4. Calculate Relative Error\n",
    "        rel_err = None\n",
    "        opt_value_display = 'N/A' # For printing\n",
    "        if opt_value is not None:\n",
    "            opt_value_display = opt_value\n",
    "            if opt_value > 0:\n",
    "                 rel_err = (quality - opt_value) / float(opt_value) # Ensure float division\n",
    "            elif opt_value == 0: # Handle optimal = 0 case\n",
    "                 # If optimal is 0, RelErr is 0 if quality is also 0, else Inf.\n",
    "                 rel_err = 0.0 if quality == 0 else float('inf')\n",
    "            else: # opt_value < 0 ? Should not happen.\n",
    "                 print(f\"  Warning: Optimal value is negative ({opt_value}) for {base_name}. RelErr calculation skipped.\")\n",
    "                 rel_err = None # Mark as not calculable\n",
    "\n",
    "            print(f\"  Result Quality: {quality}, Optimal: {opt_value_display}, RelErr: {rel_err if rel_err is not None else 'N/A':.4f}, Time: {exec_time:.4f}s\")\n",
    "\n",
    "        else: # opt_value is None (error reading file)\n",
    "             print(f\"  Result Quality: {quality}, Optimal: N/A, RelErr: N/A, Time: {exec_time:.4f}s\")\n",
    "\n",
    "\n",
    "        # 5. Write solution file\n",
    "        sol_file_base = os.path.join(output_dir, base_name) # Path for output file\n",
    "        write_solution_file(sol_file_base, method, cutoff, seed, cover_indices, quality)\n",
    "\n",
    "        # Store results for potential later analysis/table generation\n",
    "        results.append({\n",
    "            'Instance': base_name,\n",
    "            'Time': exec_time,\n",
    "            'Quality': quality,\n",
    "            'Optimal': opt_value, # Store the read optimal value\n",
    "            'RelErr': rel_err,\n",
    "            'CoveredElements': covered_count, # Store how many elements were covered\n",
    "            'UniverseSize': universe_size,\n",
    "            'Method': method\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Configuration and Execution ---\n",
    "\n",
    "DATA_DIRECTORY = \"data\"  # Assumes 'data' subdirectory exists\n",
    "CUTOFF_TIME = 600      # Nominal cutoff time (seconds), as required by spec, though greedy is usually fast\n",
    "RANDOM_SEED = None     # Not applicable for deterministic greedy\n",
    "METHOD_NAME = \"Approx\" # Algorithm identifier for file naming\n",
    "\n",
    "# Run experiments on all datasets\n",
    "all_results = []\n",
    "# Test instances\n",
    "all_results.extend(run_experiment(DATA_DIRECTORY, \"test*.in\", METHOD_NAME, CUTOFF_TIME, RANDOM_SEED))\n",
    "# Small instances\n",
    "all_results.extend(run_experiment(DATA_DIRECTORY, \"small*.in\", METHOD_NAME, CUTOFF_TIME, RANDOM_SEED))\n",
    "# Large instances\n",
    "all_results.extend(run_experiment(DATA_DIRECTORY, \"large*.in\", METHOD_NAME, CUTOFF_TIME, RANDOM_SEED))\n",
    "\n",
    "print(\"\\n--- Experiment Complete ---\")\n",
    "\n",
    "# --- Optional: Display Results Table (using pandas) ---\n",
    "# You might need to install pandas: !pip install pandas\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Format RelErr to handle potential None or inf values before displaying\n",
    "    def format_rel_err(x):\n",
    "        if x is None: return 'N/A'\n",
    "        if x == float('inf'): return 'inf'\n",
    "        if isinstance(x, (int, float)): return f\"{x:.4f}\"\n",
    "        return str(x) # Fallback\n",
    "\n",
    "    df['RelErr_Display'] = df['RelErr'].apply(format_rel_err)\n",
    "\n",
    "    # Format Time\n",
    "    df['Time'] = df['Time'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) else str(x))\n",
    "\n",
    "    print(\"\\n--- Results Summary ---\")\n",
    "    # Display key columns including the formatted RelErr\n",
    "    print(df[['Instance', 'Method', 'Time', 'Quality', 'Optimal', 'RelErr_Display']])\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nPandas not installed. Skipping results table display.\")\n",
    "    print(\"Raw results list:\")\n",
    "    # Print basic results if pandas is not available\n",
    "    for res in all_results:\n",
    "         rel_err_str = 'N/A'\n",
    "         if res['RelErr'] is not None:\n",
    "             if res['RelErr'] == float('inf'): rel_err_str = 'inf'\n",
    "             elif isinstance(res['RelErr'], (int, float)): rel_err_str = f\"{res['RelErr']:.4f}\"\n",
    "             else: rel_err_str = str(res['RelErr'])\n",
    "\n",
    "         print(f\"  {res['Instance']}: Time={res['Time']:.4f}, Quality={res['Quality']}, Optimal={res['Optimal']}, RelErr={rel_err_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e6098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
